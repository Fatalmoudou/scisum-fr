<div><p>En TAL, la performance des modèles dépend fortement de la qualité et de la quantité des données annotées. Lorsque ces ressources sont limitées, l'apprentissage actif (Active Learning) offre une solution efficace en sélectionnant les échantillons les plus pertinents à annoter. Traditionnellement, cette tâche est réalisée par des annotateurs humains, mais nous explorons ici le potentiel du grand modèle de langue Mixtral-8x7B pour générer automatiquement ces annotations. En outre, nous analysons l'influence de l'augmentation des données dans un processus d'apprentissage actif pour la reconnaissance d'entités nommées afin d'améliorer la performance des catégories sous-représentées, ainsi que l'impact du prompt et des hyper-paramètres sur la qualité des annotations générées. Les évaluations conduites sur le corpus WiNER montrent que, malgré l'absence d'annotations manuelles, cette approche permet d'obtenir des performances comparables à notre baseline, tout en réduisant de 80 % la quantité des données annotées.</p></div>