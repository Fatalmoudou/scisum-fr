L'apprentissage automatique vise la production d'une hypothèse modélisant un concept à partir d'exemples, dans le but notamment de prédire si de nouvelles observations relèvent ou non de ce concept. Parmi les algorithmes d'apprentissage, les méthodes ensemblistes combinent des hypothèses de base (dites ``faibles'') en une hypothèse globale plus performante. Le boosting, et son algorithme AdaBoost, est une méthode ensembliste très étudiée depuis plusieurs années : ses performances expérimentales remarquables reposent sur des fondements théoriques rigoureux. Il construit de manière adaptative et itérative des hypothèses de base en focalisant l'apprentissage, à chaque nouvelle itération, sur les exemples qui ont été difficiles à apprendre lors des itérations précédentes. Cependant, AdaBoost est relativement inadapté aux données du monde réel. Dans cette thèse, nous nous concentrons en particulier sur les données bruitées, et sur les données hétérogènes. Dans le cas des données bruitées, non seulement la méthode peut devenir très lente, mais surtout, AdaBoost apprend par coeur les données, et le pouvoir prédictif des hypothèses globales générées, s'en trouve extrêmement dégradé. Nous nous sommes donc intéressés à une adaptation du boosting pour traiter les données bruitées. Notre solution exploite l'information provenant d'un oracle de confiance permettant d'annihiler les effets dramatiques du bruit. Nous montrons que notre nouvel algorithme conserve les propriétés théoriques du boosting standard. Nous mettons en pratique cette nouvelle méthode, d'une part sur des données numériques, et d'autre part, de manière plus originale, sur des données textuelles. Dans le cas des données hétérogènes, aucune adaptation du boosting n'a été proposée jusqu'à présent. Pourtant, ces données, caractérisées par des attributs multiples mais de natures différentes (comme des images, du son, du texte, etc), sont extrêmement fréquentes sur le web, par exemple. Nous avons donc développé un nouvel algorithme de boosting permettant de les utiliser. Plutôt que de combiner des hypothèses boostées indépendamment, nous construisons un nouveau schéma de boosting permettant de faire collaborer durant l'apprentissage des algorithmes spécialisés sur chaque type d'attribut. Nous prouvons que les décroissances exponentielles des erreurs sont toujours assurées par ce nouveau modèle, aussi bien d'un point de vue théorique qu'expérimental.