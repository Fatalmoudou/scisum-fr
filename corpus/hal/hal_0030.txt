Le domaine des neurosciences computationnelles s'intéresse à la modélisation des fonctions cognitives à travers des modèles numériques bio-inspirés. Dans cette thèse, nous nous intéressons en particulier à l'apprentissage dans un contexte multimodal, c'est à dire à la formation de représentations cohérentes à partir de plusieurs modalités sensorielles et/ou motrices. Notre modèle s'inspire du cortex cérébral, lieu supposé de la fusion multimodale dans le cerveau, et le représente à une échelle mésoscopique par des colonnes corticales regroupées en cartes et des projections axoniques entre ces cartes. Pour effectuer nos simulations, nous proposons une bibliothèque simplifiant la construction et l'évaluation de modèles mésoscopiques. Notre modèle d'apprentissage se base sur le modèle BCM (Bienenstock-Cooper-Munro), qui propose un algorithme d'apprentissage non-supervisé local (une unité apprend à partir de ses entrées de manière autonome) et biologiquement plausible. Nous adaptons BCM en introduisant la notion d'apprentissage guidé, un moyen de biaiser la convergence de l'apprentissage BCM en faveur d'un stimulus choisi. Puis, nous mettons ce mécanisme à profit pour effectuer un co-apprentissage entre plusieurs modalités. Grâce au co-apprentissage, les sélectivités développées sur chaque modalité tendent à représenter le même phénomène, perçu à travers différentes modalités, élaborant ainsi une représentation multimodale cohérente dudit phénomène.