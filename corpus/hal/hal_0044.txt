Ce document constitue le premier chapitre de l'ouvrage [1], présentant la théorie de l'apprentissage machine selon le cadre de [19] et qui a servi de base dans la description des algorithmes d'apprentissage décrits dans les chapitres suivants. Plus particulièrement, nous présentons ici la notion de consistance qui garantit l'apprenabilité d'une fonction de prédiction. Les définitions et les hypothèses de base de cette théorie, ainsi que le principe de la minimisation du risque empirique, sont décrits dans la section 1. L'étude de la consistance de ce principe, présentée dans la section 2, nous mène au second principe de la minimisation du risque structurel, qui stipule que l'apprentissage est un compromis entre une erreur empirique faible et une capacité de la classe de fonctions forte.